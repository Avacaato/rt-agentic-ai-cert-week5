![AAIDC-wk5-l2a-intro-to-langgraph-v2.jpeg](AAIDC-wk5-l2a-intro-to-langgraph-v2.jpeg)

--DIVIDER--

---

[â¬…ï¸ Previous - From LLM Workflows to Agents](https://app.readytensor.ai/publications/Nu7EEaBmrP5C)
[â¡ï¸ Next - First LangGraph Project](https://app.readytensor.ai/publications/T8WbWCjwJ4Mm)

---

--DIVIDER--

# TL;DR

This lesson introduces LangGraph â€” a framework for building scalable, agentic systems by defining workflows as graphs. Youâ€™ll learn why LangGraph was created, how it differs from LangChain, and what makes it ideal for complex, multi-agent flows. Weâ€™ll cover the core concepts of nodes, edges, state, and super-steps â€” and explain how LangGraph lets you balance flexibility with determinism.

--DIVIDER--

:::info{title="Info"}
This lesson includes a short video quiz at the end to help you **reflect on and reinforce your understanding of LangGraph**.

ğŸ“Œ Since this is your **first introduction to LangGraph**, we recommend reading the full lesson first.
Then, test yourself with the quiz â€” itâ€™s a fun way to **check your grasp of the key ideas** before moving on.
:::

--DIVIDER--

# ğŸš§ When Static Workflows Start to Break Down

In the last lesson, we saw what happens when static workflows just canâ€™t keep up.

You started with a beautiful, minimal RAG assistant â€” a few clean function calls, maybe a memory module, some smart prompting. Life was good.

Then came the routing logic. Then conditionals. Then tool calls, loops, branching workflows, nested flows, fallback handlers, external lookups, aggregators, user clarifiersâ€¦

Soon, what began as a single chain turned into a full-blown jungle gym of agents, routes, retries, and specialized logic paths. And it was still growing.

You werenâ€™t building a simple LLM app anymore.

You were managing an **evolving system** â€” something with state, externalities, and adaptive behavior.

But your code wasnâ€™t designed for that.

--DIVIDER--

# ğŸ§­ Enter LangGraph --DIVIDER--

![langgraph-v2.jpeg](langgraph-v2.jpeg)

--DIVIDER--

What if there were a way to build agentic systems that **scale in complexity â€” without collapsing under their own weight**?

What if your LLM flows could stay **structured**, **inspectable**, and **robust** â€” even as they became more dynamic, tool-using, memory-persisting, goal-seeking agents?

Thatâ€™s what LangGraph was built for.

LangGraph is an open-source framework designed specifically for **graph-based orchestration of agentic workflows** â€” think of it as a way to give your agents a map, some structure, and a few ground rules... so they donâ€™t wander off into chaos.

In this lesson, weâ€™ll learn what LangGraph is, why it exists, and how it fits into the LangChain ecosystem. Weâ€™ll explore its core concepts â€” like **graphs**, **nodes**, **edges**, and **state** â€” and begin shifting your mental model from linear workflows to flexible flows that empower adaptive, scalable, agentic behavior.

You wonâ€™t build anything yet (thatâ€™s coming in 2b). But by the end of this lesson, youâ€™ll know exactly why LangGraph matters â€” and why it might become your favorite new tool for managing agentic systems with confidence.

Letâ€™s go.

---

--DIVIDER--

:::info{title="Info"}

 <h2>âš ï¸ LangGraph Isnâ€™t the Only Path </h2>
 
 Before we go deeper, letâ€™s pause for an honest moment.
 
 LangGraph is powerful. Itâ€™s our tool of choice in this program because it offers a **sweet spot**: the right level of flexibility and abstraction, without making you write endless boilerplate orchestration code.
 
 But itâ€™s not the only game in town â€” and itâ€™s not always the best choice.
 
 If you're building an agentic system, you might also consider:
 
 - **[Autogen](https://microsoft.github.io/autogen/)** â€” Microsoftâ€™s framework for building multi-agent conversations with advanced planning and memory-sharing.
 - **[CrewAI](https://docs.crewai.com/)** â€” a lightweight agent orchestration library that treats agents as mission-driven â€œcrew membersâ€ with specific roles.
 - **[LlamaIndex](https://www.llamaindex.ai/)** â€” a data framework focused on retrieval, indexing, and orchestration of complex LLM flows, with built-in support for agents, tools, memory, and observability.
 - **Direct SDKs** â€” you can always work directly with the APIs from LLM providers like OpenAI, Anthropic, or Cohere. This gives you maximum control â€” but it also means writing (and maintaining) all the orchestration logic yourself. And there's a catch: **if you later switch providers, your code may need major updates.** While many APIs are starting to converge around OpenAI-style function calling, there are still meaningful differences. For instance, Anthropic continues to use its own input formats and tool protocols.
 
 Each of these paths comes with tradeoffs:
 
 - Some offer more flexibility, but require you to **write and maintain a lot more code**.
 - Others are simple to start with, but **donâ€™t scale well** to complex flows or real-world needs.
 - And sometimes, good old-fashioned `if-then` statements are all you need.
 
 Weâ€™ve chosen **LangGraph** because itâ€™s a great middle ground:
 
 - Enough control to model **real agentic behavior**
 - Enough structure to prevent your system from **spiraling into chaos**
 - And enough abstraction to avoid **repeating yourself endlessly**
 
 Just remember: thereâ€™s no one-size-fits-all framework in agentic AI development.
 
 LangGraph is a great choice â€” not the only choice. Use it when it helps. Reach for something else when it doesnâ€™t.
 
 :::
 
 ---

--DIVIDER--

# ğŸ”§ LangGraph in the LangChain Ecosystem

--DIVIDER--

![langchain-or-langgraph.jpeg](langchain-or-langgraph.jpeg)

--DIVIDER--

You might be wondering:  
 **Isnâ€™t LangGraph just part of LangChain? Whatâ€™s new here?**

Fair question â€” especially if youâ€™ve used LangChain agents before.

LangGraph is built by the same team, and it works great with LangChain components like tools, memory, retrievers, and chains. But itâ€™s a **separate framework** with a different purpose.

LangChain is about **building blocks** â€” prompts, chains, tools, memory.  
 LangGraph is about **flow control** â€” how those blocks connect, branch, retry, loop, and evolve over time.

Use the following as guide:

> If your workflow is a Directed Acyclic Graph (DAG), use LangChain.
> If itâ€™s complex, cyclical, or iterative â€” you might want to reach for LangGraph.

You can use LangGraph with LangChain, without LangChain, or even without LLMs. Itâ€™s just Python â€” built for scaling agentic workflows with structure and safety.

Theyâ€™re designed to work together â€” but they solve different problems.

LangChain is great for predictable flows.  
 LangGraph is built for **dynamic, multi-agent systems** that adapt and evolve.

---

--DIVIDER--

# ğŸ§± Core Components of LangGraph

LangGraph is built on four core building blocks: **state**, **nodes**, **edges**, and **graphs**.

--DIVIDER--

![langgraph-core-components.jpg](langgraph-core-components.jpg)

--DIVIDER--

Once you understand these, you can build anything from tool-using assistants to multi-agent systems with complex feedback loops. Letâ€™s walk through them in the right order.

---

## ğŸ§  State

State refers to the current context of your workflow. It is represented as Pydantic object or a Typed Dict that carries all relevant information as your workflow runs. This might include:

- The original user input
- Intermediate outputs
- Flags or counters
- Anything your system needs to remember or reason about

Every function in your graph will receive the current state, do something useful, and return an updated version.

---

## ğŸ”¹ Nodes

**Nodes** are the functional building blocks of your system.

**Each node is just a function**. It receives the current state, performs a step of work (like calling an LLM, using a tool, or some other non-LLM logic), and returns a new version of the state.

You can keep nodes simple or pack them with logic â€” LangGraph doesnâ€™t care. All that matters is: **state in â†’ state out**.

It is important to emphasize - nodes can be any functions, not just LLM calls. You can use regular Python functions, external APIs, or any callable that fits your workflow.

---

## â¡ï¸ Edges

**Edges** define the flow from one node to the next.

Sometimes that flow is fixed â€” â€œafter this node, go to the next one.â€

But often itâ€™s **conditional**: you decide what happens next based on the current state (i.e. output from the previous node).

This makes your workflow dynamic. For example:

- Route to different tools based on detected intent
- Retry or clarify if the output isn't good enough
- Skip unnecessary steps based on progress so far

Instead of hardcoding the logic flow, you let the system adapt its own path â€” based on what it just learned.

---

## ğŸ” Graph

The **graph** is the structure that ties everything together.

You define:

- The available nodes
- How theyâ€™re connected with edges
- Where the flow begins and ends

LangGraph uses this structure to execute your workflow from start to finish â€” moving through nodes, routing based on conditions, and evolving the state along the way.

The graph is your systemâ€™s brainstem â€” not doing the thinking itself, but connecting all the parts so the thinking can happen.

---

--DIVIDER--

# âš™ï¸ Building and Running a LangGraph

Now that youâ€™ve seen the core components â€” state, nodes, edges, and graphs â€” hereâ€™s the good news:

> Youâ€™ll follow the same five steps every time you build with LangGraph.

This pattern holds whether youâ€™re building a two-node assistant or a multi-agent workflow with loops and retries.

## ğŸ› ï¸ The 5-Step LangGraph Workflow

 <h3>1. Define the state</h3>
 
 Decide what information your system needs to carry throughout the workflow. Use a Pydantic model (or typed dictionary/dataclass) to define the structure â€” like current category, user choice, or a list of past jokes.
 
 <h3>2. Write your node functions</h3>
 
 Each node is just a Python function. It receives the current state and returns an updated version â€” either fully or partially. Nodes can do anything: call an API, update a value, print something, or fetch a joke (like weâ€™ll do here).
 
 <h3>3. Create a graph builder</h3>
 
 Instantiate a `StateGraph`, specifying the state type. Think of this as preparing a blank map before plotting your logic.
 
 <h3>4. Add nodes and edges</h3>
 
 Register your node functions and define how they connect. Use fixed edges or conditional routing logic based on values in the state.
 
 <h3>5. Compile and run the graph</h3>
 
 Once everything is wired up, compile the graph. This gives you an executable workflow that you can run with:
 
 ```python
 graph.invoke(initial_state)
 ```
 ---

--DIVIDER--

# How LangGraph Executes: Reducers, Super-Steps & State Persistence

--DIVIDER--

## ğŸ”„ Reducer Functions: How State Updates Work

When multiple nodes try to update the same piece of state â€” either in parallel or sequentially â€” how does LangGraph decide what the final value should be?

LangGraph solves this with **reducer functions** â€” optional functions you attach to fields in your state class. They define how to merge the current value with a new update:

```python
(current_value, new_value) -> merged_value
```

This lets you handle concurrent updates safely and predictably.

 <h3> ğŸ§© Common Reducer Patterns (with Class Examples) </h3>
 
 <h4> âœ… Default (Overwrite)</h4>
 
 This is the default behavior. New values overwrite the old ones â€” no reducer needed.
 
 ```python
 from pydantic import BaseModel
 
 class State(BaseModel):
     messages: str  # Default: overwrite
 ```
 
 
 <h4>â•Append to Messages (LLM Chat Apps)</h4>
 
 LangGraph provides a special reducer for appending chat messages.
 
 ```python
 from pydantic import BaseModel
 from typing import Annotated
 from langgraph.graph.message import add_messages
 
 class State(BaseModel):
     messages: Annotated[list, add_messages]
 ```
 
 <h4>â•Append to Generic Lists</h4>
 
 For accumulating lists of items â€” e.g. documents, tool responses.
 
 ```python
 from pydantic import BaseModel
 from typing import Annotated
 from operator import add
 
 class State(BaseModel):
     results: Annotated[list, add]
 ```
 
 <h4>ğŸ”¢Sum or Count</h4>
 
 For tracking scores, token usage, or retry attempts:
 
 ```python
 from pydantic import BaseModel
 from typing import Annotated
 from operator import add
 
 class State(BaseModel):
     total_cost: Annotated[int, add]
 ```
 
 <h4>ğŸ§ Custom Merge Logic</h4>
 
 Use a custom reducer for more complex structures like merging dicts:
 
 ```python
 from pydantic import BaseModel
 from typing import Annotated
 
 def merge_user_data(current: dict, update: dict) -> dict:
     merged = current.copy()
     merged.update(update)
     return merged
 
 class State(BaseModel):
     user_profile: Annotated[dict, merge_user_data]
 ```
 
 <h3>Why This Matters</h3>
 
 Without reducers, youâ€™d need to manually handle state conflicts â€” especially when running nodes in parallel.
 
 Reducers let you:
 
 * **Merge state cleanly** when multiple nodes contribute
 * **Avoid accidental overwrites** or race conditions
 * **Build flows that evolve naturally** over time
 
 Think of reducers as your **rules for safe collaboration** â€” whether among nodes, agents, or tools.
 
 > âš ï¸ Donâ€™t worry if this feels abstract â€” weâ€™ll see reducers in action in the next lesson.

--DIVIDER--

## â–¶ï¸ Super-Steps: How a Graph Actually Runs

So what happens when you run a LangGraph?

Every time you call `graph.invoke()` (or `graph.run()`), LangGraph performs whatâ€™s called a **super-step**.

A super-step is a single pass through the graph â€” starting at the current node(s), executing any eligible logic, and updating the state accordingly.

Depending on your routing logic, a super-step may:

- Run just one node and move forward
- Trigger multiple nodes to run in parallel
- Loop back to earlier nodes
- Or terminate the flow, if no more edges apply

Each super-step:

- Receives a snapshot of the current state
- Executes one or more nodes
- Produces a new state
- Decides what node(s) to visit next

LangGraph continues running super-steps **until the flow completes** â€” i.e., no active nodes remain.

 <h3>ğŸ§ Human-in-the-Loop Pauses </h3> 
 
 LangGraph supports **human-in-the-loop workflows** â€” for example, asking for manual review or approval.
 
 When your graph pauses to wait for input (e.g., via an "await user response" node), execution **stops at that point**. You can store the state, send a notification, and pick things up later.
 
 When you resume the graph, you're starting a **new super-step** â€” with the last known state as your input.
 
 <h3> ğŸ’¾ Persisting State Between Super-Steps </h3>
  
 âš ï¸**Important:** LangGraph doesnâ€™t persist state for you by default.  
 If you're building multi-session flows, **you must save the state** between super-steps (e.g., to a database or file).
 
 <h3> Why this matters </h3> 
 This super-step model makes LangGraph:
 
 - **Interruptible** â€” perfect for long-running or human-in-the-loop flows
 - **Inspectable** â€” every state change is traceable
 - **Deterministic** â€” same inputs yield the same results (unless you add randomness)
 
 You donâ€™t have to manage any of this manually. Just define your nodes, edges, and state â€” and LangGraph handles the orchestration for you.
 
---

--DIVIDER--

# ğŸ§  Core Strengths of LangGraph

Once you start building with LangGraph, a few things stand out. These arenâ€™t just conveniences â€” they solve real problems that come up fast in agentic systems.

## 1. âœ… Memory Management Made Easy

In many agent frameworks, memory is bolted on â€” you have to manually track what was said, what tools were used, or what plans were made.

In LangGraph, your **state is your memory** â€” and every node has access to it.  
 No special wrapper required. No callback hell.

Want to persist memory across sessions? Just save the state object. Done.

## 2. ğŸ•°ï¸ Checkpointing and Time Travel

LangGraph automatically tracks every state update â€” which means you can:

- Resume flows from a saved point
- Rewind and inspect earlier decisions
- Debug what happened and why

This is especially useful for:

- Long-running or asynchronous tasks
- Human-in-the-loop approvals
- Recovery from failed tool calls or invalid inputs

You donâ€™t have to build your own session store or audit log. LangGraph handles it out of the box.

## 3. ğŸ”€ Safe Parallel Execution

LangGraph lets you define **multiple outgoing edges** from a node and run them in parallel. Thatâ€™s hard to do safely in most frameworks.

LangGraph handles concurrent state updates safely through **reducer** functions.
When parallel nodes both try to update the same part of state, the reducer function determines how to merge their contributions â€” whether that's appending to a list, taking the maximum value, or applying custom logic.
This means you can have multiple agents working on different aspects of a problem simultaneously, without worrying about race conditions or lost updates.

## 4. ğŸ§© Configurables and Personalization

LangGraph supports **configurables** â€” parameters that can change per user, thread, or session.

You can define different flows, memory settings, or behaviors for different users â€” all using the same underlying graph. This makes it easier to build personalized assistants or per-user logic at scale.

---

--DIVIDER--

# ğŸ¥ Reflect and Test Your Understanding

Before you move on, take a moment to **step back and think**.

This short video quiz wonâ€™t give you the answers â€” but it will challenge your assumptions, stretch your thinking, and help you spot the **core ideas** behind LangGraph and agentic AI design.

Itâ€™s not about memorization. Itâ€™s about **intuition**.

ğŸ‘‰ **Watch the video** and see how many questions you can reason through:

:::youtube[Title]{#Px1Yj4rYN0A}

---

--DIVIDER--

# ğŸ§­ Whatâ€™s Next: From Concepts to Code

Now that you know how LangGraph works â€” and why it matters â€” itâ€™s time to build.

In **Lesson 2b**, youâ€™ll define your own state, add nodes, connect them with edges, and run your first real agentic flow.

Letâ€™s go.

--DIVIDER--

---

[â¬…ï¸ Previous - From LLM Workflows to Agents](https://app.readytensor.ai/publications/Nu7EEaBmrP5C)
[â¡ï¸ Next - First LangGraph Project](https://app.readytensor.ai/publications/T8WbWCjwJ4Mm)

---
